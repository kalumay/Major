{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11h8hTiYdMCEXxa93_PzmKe5QmdojOxAs",
      "authorship_tag": "ABX9TyPhC/On5PaXpxeyWHpus5Uz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalumay/Major/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdzjOEURO3NS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOU5FvodO-p4",
        "outputId": "54c39855-8f35-4b81-dd44-09a53136001d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path='/content/drive/MyDrive/Colab Notebooks/Datas/'"
      ],
      "metadata": {
        "id": "-npuJdA7O_o3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "ds=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datas/labeled_data.csv/labeled_data.csv')"
      ],
      "metadata": {
        "id": "eebx1SZXPEiR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds.to_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCJuCVeGPHGx",
        "outputId": "384d821f-381e-4715-e529-ed5965d8f877"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.to_string of        Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0               0      3            0                   0        3      2   \n",
            "1               1      3            0                   3        0      1   \n",
            "2               2      3            0                   3        0      1   \n",
            "3               3      3            0                   2        1      1   \n",
            "4               4      6            0                   6        0      1   \n",
            "...           ...    ...          ...                 ...      ...    ...   \n",
            "24778       25291      3            0                   2        1      1   \n",
            "24779       25292      3            0                   1        2      2   \n",
            "24780       25294      3            0                   3        0      1   \n",
            "24781       25295      6            0                   6        0      1   \n",
            "24782       25296      3            0                   0        3      2   \n",
            "\n",
            "                                                   tweet  \n",
            "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
            "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
            "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
            "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
            "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
            "...                                                  ...  \n",
            "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
            "24779  you've gone and broke the wrong heart baby, an...  \n",
            "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
            "24781              youu got wild bitches tellin you lies  \n",
            "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
            "\n",
            "[24783 rows x 7 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in ds.columns:\n",
        "    print(f\"\\nColumn: {column}\")\n",
        "    print(ds[column].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LvE6KXLPJ4A",
        "outputId": "ead4e240-601c-492a-859d-3143e3ce90c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Column: Unnamed: 0\n",
            "0        1\n",
            "16934    1\n",
            "16907    1\n",
            "16906    1\n",
            "16905    1\n",
            "        ..\n",
            "8487     1\n",
            "8486     1\n",
            "8485     1\n",
            "8484     1\n",
            "25296    1\n",
            "Name: Unnamed: 0, Length: 24783, dtype: int64\n",
            "\n",
            "Column: count\n",
            "3    22807\n",
            "6     1571\n",
            "4      211\n",
            "9      167\n",
            "7       27\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: hate_speech\n",
            "0    19790\n",
            "1     3419\n",
            "2     1251\n",
            "3      287\n",
            "4       21\n",
            "5        7\n",
            "6        5\n",
            "7        3\n",
            "Name: hate_speech, dtype: int64\n",
            "\n",
            "Column: offensive_language\n",
            "3    13383\n",
            "2     4246\n",
            "0     3475\n",
            "1     2066\n",
            "6      857\n",
            "5      369\n",
            "4      251\n",
            "9       66\n",
            "8       37\n",
            "7       33\n",
            "Name: offensive_language, dtype: int64\n",
            "\n",
            "Column: neither\n",
            "0    18892\n",
            "3     2790\n",
            "1     1694\n",
            "2     1200\n",
            "6      103\n",
            "5       54\n",
            "4       35\n",
            "9        5\n",
            "8        5\n",
            "7        5\n",
            "Name: neither, dtype: int64\n",
            "\n",
            "Column: class\n",
            "1    19190\n",
            "2     4163\n",
            "0     1430\n",
            "Name: class, dtype: int64\n",
            "\n",
            "Column: tweet\n",
            "!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...          1\n",
            "RT @MurderHigashi: I cannot be worried 'bout no bitch.                                                                                                1\n",
            "RT @MrPerfect_22: Most of these niggas go broke for these hoes !!                                                                                     1\n",
            "RT @MrPOONsoaker: Foh RT @Thotcho: @MrPOONsoaker lmao 6&#8242;0 but I&#8217;m hella skinny so bitches don&#8217;t like me                             1\n",
            "RT @MrNationWide: fake eyelashes are okay if they look natural, but some of you bitches look like you gonna take flight if you blink too fa&#8230;    1\n",
            "                                                                                                                                                     ..\n",
            "But she can shade the shit out a bitch RT @axolROSE: #YourWifeCantRead                                                                                1\n",
            "But she a bad bad bitch make you late for it.                                                                                                         1\n",
            "But rich is a light skin coon. So it's expected.                                                                                                      1\n",
            "But not prettier than Amber's. RT @YumiYoko: Her pussy is pretty                                                                                      1\n",
            "~~Ruffled | Ntac Eileen Dahlia - Beautiful color combination of pink, orange, yellow &amp; white. A Coll http://t.co/H0dYEBvnZB                       1\n",
            "Name: tweet, Length: 24783, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['tweet'] = ds['tweet'].str.lower()\n"
      ],
      "metadata": {
        "id": "6pN3JdyM1xh3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_clean = ['tweet']  # Replace with actual column names\n",
        "\n",
        "# Remove words starting with \"@\" in the specified columns\n",
        "for column in columns_to_clean:\n",
        "    ds[column] = ds[column].str.replace(r'\\S*@\\S*', '', regex=True)\n",
        "\n",
        "print(ds)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4mWA-8mPNRl",
        "outputId": "846109b1-5832-4575-fd27-d9c58e1b70ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0               0      3            0                   0        3      2   \n",
            "1               1      3            0                   3        0      1   \n",
            "2               2      3            0                   3        0      1   \n",
            "3               3      3            0                   2        1      1   \n",
            "4               4      6            0                   6        0      1   \n",
            "...           ...    ...          ...                 ...      ...    ...   \n",
            "24778       25291      3            0                   2        1      1   \n",
            "24779       25292      3            0                   1        2      2   \n",
            "24780       25294      3            0                   3        0      1   \n",
            "24781       25295      6            0                   6        0      1   \n",
            "24782       25296      3            0                   0        3      2   \n",
            "\n",
            "                                                   tweet  \n",
            "0      !!! rt  as a woman you shouldn't complain abou...  \n",
            "1      !!!!! rt  boy dats cold...tyga dwn bad for cuf...  \n",
            "2      !!!!!!! rt  dawg!!!! rt  you ever fuck a bitch...  \n",
            "3                  !!!!!!!!! rt   she look like a tranny  \n",
            "4      !!!!!!!!!!!!! rt  the shit you hear about me m...  \n",
            "...                                                  ...  \n",
            "24778  you's a muthaf***in lie    right! his tl is tr...  \n",
            "24779  you've gone and broke the wrong heart baby, an...  \n",
            "24780  young buck wanna eat!!.. dat nigguh like i ain...  \n",
            "24781              youu got wild bitches tellin you lies  \n",
            "24782  ~~ruffled | ntac eileen dahlia - beautiful col...  \n",
            "\n",
            "[24783 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_65 = ds.iloc[66]\n",
        "print(row_65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwS1b2ioPhA3",
        "outputId": "0a538718-d0ab-40b7-cd8b-e59934df71c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0                                                          66\n",
            "count                                                                3\n",
            "hate_speech                                                          0\n",
            "offensive_language                                                   1\n",
            "neither                                                              2\n",
            "class                                                                2\n",
            "tweet                  http://t.co/3gzupfumev\" woof woof and hot soles\n",
            "Name: 66, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_clean = ['tweet']  # Replace with actual column names\n",
        "\n",
        "# Clean special characters in the specified columns\n",
        "for column in columns_to_clean:\n",
        "    ds[column] = ds[column].str.replace('[^a-zA-Z0-9\\s]', '', regex=True)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHeoN8ZcP2lL",
        "outputId": "fd348be2-f3fd-4006-8dd8-6423785a4c4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0               0      3            0                   0        3      2   \n",
            "1               1      3            0                   3        0      1   \n",
            "2               2      3            0                   3        0      1   \n",
            "3               3      3            0                   2        1      1   \n",
            "4               4      6            0                   6        0      1   \n",
            "...           ...    ...          ...                 ...      ...    ...   \n",
            "24778       25291      3            0                   2        1      1   \n",
            "24779       25292      3            0                   1        2      2   \n",
            "24780       25294      3            0                   3        0      1   \n",
            "24781       25295      6            0                   6        0      1   \n",
            "24782       25296      3            0                   0        3      2   \n",
            "\n",
            "                                                   tweet  \n",
            "0       rt  as a woman you shouldnt complain about cl...  \n",
            "1       rt  boy dats coldtyga dwn bad for cuffin dat ...  \n",
            "2       rt  dawg rt  you ever fuck a bitch and she st...  \n",
            "3                            rt   she look like a tranny  \n",
            "4       rt  the shit you hear about me might be true ...  \n",
            "...                                                  ...  \n",
            "24778  yous a muthafin lie    right his tl is trash 8...  \n",
            "24779  youve gone and broke the wrong heart baby and ...  \n",
            "24780  young buck wanna eat dat nigguh like i aint fu...  \n",
            "24781              youu got wild bitches tellin you lies  \n",
            "24782  ruffled  ntac eileen dahlia  beautiful color c...  \n",
            "\n",
            "[24783 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_55 = ds.iloc[56]\n",
        "print(row_55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h3IDR9gSI4v",
        "outputId": "bab041d4-b5d7-4ab7-9917-e58fa2d00e38"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0                                                           56\n",
            "count                                                                 3\n",
            "hate_speech                                                           0\n",
            "offensive_language                                                    3\n",
            "neither                                                               0\n",
            "class                                                                 1\n",
            "tweet                  and ima steal his cat n replace it with a pit...\n",
            "Name: 56, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with null values in the specified columns\n",
        "ds.dropna(subset=columns_to_clean, inplace=True)\n",
        "\n",
        "# Display the DataFrame after removing null values\n",
        "print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRY2JhbVSS1d",
        "outputId": "9c82135d-9e63-4e7f-ad26-93979615aca6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0               0      3            0                   0        3      2   \n",
            "1               1      3            0                   3        0      1   \n",
            "2               2      3            0                   3        0      1   \n",
            "3               3      3            0                   2        1      1   \n",
            "4               4      6            0                   6        0      1   \n",
            "...           ...    ...          ...                 ...      ...    ...   \n",
            "24778       25291      3            0                   2        1      1   \n",
            "24779       25292      3            0                   1        2      2   \n",
            "24780       25294      3            0                   3        0      1   \n",
            "24781       25295      6            0                   6        0      1   \n",
            "24782       25296      3            0                   0        3      2   \n",
            "\n",
            "                                                   tweet  \n",
            "0       rt  as a woman you shouldnt complain about cl...  \n",
            "1       rt  boy dats coldtyga dwn bad for cuffin dat ...  \n",
            "2       rt  dawg rt  you ever fuck a bitch and she st...  \n",
            "3                            rt   she look like a tranny  \n",
            "4       rt  the shit you hear about me might be true ...  \n",
            "...                                                  ...  \n",
            "24778  yous a muthafin lie    right his tl is trash 8...  \n",
            "24779  youve gone and broke the wrong heart baby and ...  \n",
            "24780  young buck wanna eat dat nigguh like i aint fu...  \n",
            "24781              youu got wild bitches tellin you lies  \n",
            "24782  ruffled  ntac eileen dahlia  beautiful color c...  \n",
            "\n",
            "[24783 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download NLTK stopwords data\n",
        "nltk.download('stopwords')\n",
        "\n",
        "columns_to_clean = ['tweet']  # Replace with actual column names\n",
        "\n",
        "# Remove stopwords in the specified columns\n",
        "stop_words = set(stopwords.words('english'))\n",
        "for column in columns_to_clean:\n",
        "    ds[column] = ds[column].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Display the DataFrame after removing stopwords\n",
        "print(ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9iOEi7DS3rs",
        "outputId": "513cfe59-de02-45e7-c11e-1321381ef198"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0               0      3            0                   0        3      2   \n",
            "1               1      3            0                   3        0      1   \n",
            "2               2      3            0                   3        0      1   \n",
            "3               3      3            0                   2        1      1   \n",
            "4               4      6            0                   6        0      1   \n",
            "...           ...    ...          ...                 ...      ...    ...   \n",
            "24778       25291      3            0                   2        1      1   \n",
            "24779       25292      3            0                   1        2      2   \n",
            "24780       25294      3            0                   3        0      1   \n",
            "24781       25295      6            0                   6        0      1   \n",
            "24782       25296      3            0                   0        3      2   \n",
            "\n",
            "                                                   tweet  \n",
            "0      rt woman shouldnt complain cleaning house amp ...  \n",
            "1      rt boy dats coldtyga dwn bad cuffin dat hoe 1s...  \n",
            "2      rt dawg rt ever fuck bitch start cry confused ...  \n",
            "3                                    rt look like tranny  \n",
            "4      rt shit hear might true might faker bitch told...  \n",
            "...                                                  ...  \n",
            "24778  yous muthafin lie right tl trash 8230 mine bib...  \n",
            "24779  youve gone broke wrong heart baby drove rednec...  \n",
            "24780  young buck wanna eat dat nigguh like aint fuck...  \n",
            "24781                  youu got wild bitches tellin lies  \n",
            "24782  ruffled ntac eileen dahlia beautiful color com...  \n",
            "\n",
            "[24783 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_clean = ['tweet']  # Replace with actual column names\n",
        "\n",
        "# Remove \"RT\" in the specified columns\n",
        "for column in columns_to_clean:\n",
        "    ds[column] = ds[column].str.replace(r'\\brt\\b', '', regex=True)\n",
        "\n",
        "print(ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Oy8rMWPUftq",
        "outputId": "5cf20d55-54e1-4985-a760-dcd17446c2f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0               0      3            0                   0        3      2   \n",
            "1               1      3            0                   3        0      1   \n",
            "2               2      3            0                   3        0      1   \n",
            "3               3      3            0                   2        1      1   \n",
            "4               4      6            0                   6        0      1   \n",
            "...           ...    ...          ...                 ...      ...    ...   \n",
            "24778       25291      3            0                   2        1      1   \n",
            "24779       25292      3            0                   1        2      2   \n",
            "24780       25294      3            0                   3        0      1   \n",
            "24781       25295      6            0                   6        0      1   \n",
            "24782       25296      3            0                   0        3      2   \n",
            "\n",
            "                                                   tweet  \n",
            "0       woman shouldnt complain cleaning house amp ma...  \n",
            "1       boy dats coldtyga dwn bad cuffin dat hoe 1st ...  \n",
            "2          dawg  ever fuck bitch start cry confused shit  \n",
            "3                                       look like tranny  \n",
            "4       shit hear might true might faker bitch told y...  \n",
            "...                                                  ...  \n",
            "24778  yous muthafin lie right tl trash 8230 mine bib...  \n",
            "24779  youve gone broke wrong heart baby drove rednec...  \n",
            "24780  young buck wanna eat dat nigguh like aint fuck...  \n",
            "24781                  youu got wild bitches tellin lies  \n",
            "24782  ruffled ntac eileen dahlia beautiful color com...  \n",
            "\n",
            "[24783 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK tokenization data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Specify the column(s) you want to tokenize\n",
        "columns_to_tokenize = ['tweet']  # Replace with actual column names\n",
        "\n",
        "# Convert the column to string type\n",
        "ds['tweet'] = ds['tweet'].astype(str)\n",
        "\n",
        "# Tokenize text in the specified columns\n",
        "for column in columns_to_tokenize:\n",
        "    ds['tweet'] = ds['tweet'].apply(lambda x: word_tokenize(x))\n",
        "\n",
        "# Display the DataFrame after tokenization\n",
        "print(ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-04AnSYU9HA",
        "outputId": "7b94a331-ef21-4343-c9f2-8534a1eb1e00"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0               0      3            0                   0        3      2   \n",
            "1               1      3            0                   3        0      1   \n",
            "2               2      3            0                   3        0      1   \n",
            "3               3      3            0                   2        1      1   \n",
            "4               4      6            0                   6        0      1   \n",
            "...           ...    ...          ...                 ...      ...    ...   \n",
            "24778       25291      3            0                   2        1      1   \n",
            "24779       25292      3            0                   1        2      2   \n",
            "24780       25294      3            0                   3        0      1   \n",
            "24781       25295      6            0                   6        0      1   \n",
            "24782       25296      3            0                   0        3      2   \n",
            "\n",
            "                                                   tweet  \n",
            "0      [[, 'woman, ', ,, 'shouldnt, ', ,, 'complain, ...  \n",
            "1      [[, 'boy, ', ,, 'dats, ', ,, 'coldtyga, ', ,, ...  \n",
            "2      [[, 'dawg, ', ,, 'ever, ', ,, 'fuck, ', ,, 'bi...  \n",
            "3           [[, 'look, ', ,, 'like, ', ,, 'tranny, ', ]]  \n",
            "4      [[, 'shit, ', ,, 'hear, ', ,, 'might, ', ,, 't...  \n",
            "...                                                  ...  \n",
            "24778  [[, 'yous, ', ,, 'muthafin, ', ,, 'lie, ', ,, ...  \n",
            "24779  [[, 'youve, ', ,, 'gone, ', ,, 'broke, ', ,, '...  \n",
            "24780  [[, 'young, ', ,, 'buck, ', ,, 'wan, ', ,, 'na...  \n",
            "24781  [[, 'youu, ', ,, 'got, ', ,, 'wild, ', ,, 'bit...  \n",
            "24782  [[, 'ruffled, ', ,, 'ntac, ', ,, 'eileen, ', ,...  \n",
            "\n",
            "[24783 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert the tokenized text back to string\n",
        "ds['tweet'] = ds['tweet'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Create a TF-IDF Vectorizer instance\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 1))  # Adjust parameters as needed\n",
        "\n",
        "# Fit and transform the text data\n",
        "X_tfidf = vectorizer.fit_transform(ds['tweet'])\n",
        "\n",
        "# Display the feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"Feature names:\", feature_names)\n",
        "\n",
        "# Display the TF-IDF matrix\n",
        "print(\"TF-IDF matrix:\")\n",
        "print(X_tfidf.toarray())\n"
      ],
      "metadata": {
        "id": "M8YmIOq9Mlbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52db3339-d84a-4291-bf5f-2cfb2f91bcc3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names: ['10' '100' '1000' ... 'zip' 'zone' 'zoo']\n",
            "TF-IDF matrix:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'ds' is your DataFrame and 'target' is the column with labels\n",
        "y = ds['class']\n",
        "\n",
        "# Display class distribution\n",
        "class_distribution = y.value_counts()\n",
        "print(\"Class Distribution:\")\n",
        "print(class_distribution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwdXsL6WVuNz",
        "outputId": "edbb8e4e-001f-40d4-e5c2-7734e2e6743c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "1    19190\n",
            "2     4163\n",
            "0     1430\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define feature matrix 'X' and target variable 'y'\n",
        "X = ds[['tweet']]  # Features\n",
        "y = ds[['class']]  # Targets\n",
        "\n",
        "# Split the data into training and testing sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Display the modified target variable 'y'\n",
        "print(\"Modified Target Variable 'y':\")\n",
        "print(y)\n",
        "# Display feature matrix 'X'\n",
        "print(\"Feature Matrix 'X':\")\n",
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hZAnqCzdlVP",
        "outputId": "4b5df72a-0d5b-49e3-def2-dff94f2893ca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified Target Variable 'y':\n",
            "       class\n",
            "0          2\n",
            "1          1\n",
            "2          1\n",
            "3          1\n",
            "4          1\n",
            "...      ...\n",
            "24778      1\n",
            "24779      2\n",
            "24780      1\n",
            "24781      1\n",
            "24782      2\n",
            "\n",
            "[24783 rows x 1 columns]\n",
            "Feature Matrix 'X':\n",
            "                                                   tweet\n",
            "0      [ 'woman ' , 'shouldnt ' , 'complain ' , 'clea...\n",
            "1      [ 'boy ' , 'dats ' , 'coldtyga ' , 'dwn ' , 'b...\n",
            "2      [ 'dawg ' , 'ever ' , 'fuck ' , 'bitch ' , 'st...\n",
            "3                      [ 'look ' , 'like ' , 'tranny ' ]\n",
            "4      [ 'shit ' , 'hear ' , 'might ' , 'true ' , 'mi...\n",
            "...                                                  ...\n",
            "24778  [ 'yous ' , 'muthafin ' , 'lie ' , 'right ' , ...\n",
            "24779  [ 'youve ' , 'gone ' , 'broke ' , 'wrong ' , '...\n",
            "24780  [ 'young ' , 'buck ' , 'wan ' , 'na ' , 'eat '...\n",
            "24781  [ 'youu ' , 'got ' , 'wild ' , 'bitches ' , 't...\n",
            "24782  [ 'ruffled ' , 'ntac ' , 'eileen ' , 'dahlia '...\n",
            "\n",
            "[24783 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'tweet' is your text feature, and 'class' is the target variable\n",
        "X = ds['tweet'].astype(str)\n",
        "y = ds['class']\n",
        "\n",
        "# Function to remove digits from a string\n",
        "def remove_digits(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Apply the function to remove digits from the 'tweet' column\n",
        "X = X.apply(remove_digits)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"Original Class Distribution:\", Counter(y_train))\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Resampled Class Distribution:\", Counter(y_resampled))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL3zt47q2z9P",
        "outputId": "b59b43ab-873c-4c20-c5e0-f305f6f81f77"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Class Distribution: Counter({1: 15352, 2: 3330, 0: 1144})\n",
            "Resampled Class Distribution: Counter({1: 15352, 2: 15352, 0: 15352})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"num test tweet: {y_test.shape[0]}\")\n",
        "print(f\"num train tweet: {y_train.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvGa5SGKhO7u",
        "outputId": "86573b77-09d2-45c0-bc7e-83855337f90e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num test tweet: 4957\n",
            "num train tweet: 19826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the true labels (ground truth) from dataset\n",
        "y_true = ds[['class']]\n",
        "\n",
        "random_predictions = np.random.randint(2, size=(len(ds), 1))\n",
        "\n",
        "# Convert the array of predictions to a DataFrame with appropriate column names\n",
        "y_pred = pd.DataFrame(random_predictions, columns=['class'])"
      ],
      "metadata": {
        "id": "Pglq_bH8iFoL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data Types in y_true:\")\n",
        "print(y_true.dtypes)\n",
        "\n",
        "print(\"\\nData Types in y_pred:\")\n",
        "print(y_pred.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "882I_0t3jNrt",
        "outputId": "09ea47d5-0e2e-4c27-b9f3-e6b4f4b3bde8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Types in y_true:\n",
            "class    int64\n",
            "dtype: object\n",
            "\n",
            "Data Types in y_pred:\n",
            "class    int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Flatten multi-class targets into a single column\n",
        "label_encoder = LabelEncoder()\n",
        "y_true_flat = label_encoder.fit_transform(y_true.values.argmax(axis=1))\n",
        "y_pred_flat = label_encoder.transform(y_pred.values.argmax(axis=1))\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true_flat, y_pred_flat)\n",
        "precision = precision_score(y_true_flat, y_pred_flat, average='weighted')\n",
        "recall = recall_score(y_true_flat, y_pred_flat, average='weighted')\n",
        "f1 = f1_score(y_true_flat, y_pred_flat, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true_flat, y_pred_flat)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCrs6FoPaAU9",
        "outputId": "b1bd7966-e161-49f9-8170-5a6e17997259"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "Confusion Matrix:\n",
            "[[24783]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_106 = ds.iloc[107]\n",
        "print(row_106)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZiAeKBEM2AA",
        "outputId": "b40e8d4e-a821-423a-bb7c-d3339ade6b50"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0                                                          108\n",
            "count                                                                 3\n",
            "hate_speech                                                           0\n",
            "offensive_language                                                    3\n",
            "neither                                                               0\n",
            "class                                                                 1\n",
            "tweet                 [ 'check ' , '12th ' , 'man ' , 'cowboysnation...\n",
            "Name: 107, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'tweet' is the column with tweets in your DataFrame\n",
        "ds['tweet'] = ds['tweet'].apply(lambda x: ' '.join([PorterStemmer().stem(word) for word in x.split()]))\n",
        "\n",
        "# Display the DataFrame after stemming\n",
        "print(ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVNRnJU0Drdn",
        "outputId": "a26eaa55-9084-424f-fdbc-db214a931b6b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0               0      3            0                   0        3      2   \n",
            "1               1      3            0                   3        0      1   \n",
            "2               2      3            0                   3        0      1   \n",
            "3               3      3            0                   2        1      1   \n",
            "4               4      6            0                   6        0      1   \n",
            "...           ...    ...          ...                 ...      ...    ...   \n",
            "24778       25291      3            0                   2        1      1   \n",
            "24779       25292      3            0                   1        2      2   \n",
            "24780       25294      3            0                   3        0      1   \n",
            "24781       25295      6            0                   6        0      1   \n",
            "24782       25296      3            0                   0        3      2   \n",
            "\n",
            "                                                   tweet  \n",
            "0      [ 'woman ' , 'shouldnt ' , 'complain ' , 'clea...  \n",
            "1      [ 'boy ' , 'dat ' , 'coldtyga ' , 'dwn ' , 'ba...  \n",
            "2      [ 'dawg ' , 'ever ' , 'fuck ' , 'bitch ' , 'st...  \n",
            "3                      [ 'look ' , 'like ' , 'tranni ' ]  \n",
            "4      [ 'shit ' , 'hear ' , 'might ' , 'true ' , 'mi...  \n",
            "...                                                  ...  \n",
            "24778  [ 'you ' , 'muthafin ' , 'lie ' , 'right ' , '...  \n",
            "24779  [ 'youv ' , 'gone ' , 'broke ' , 'wrong ' , 'h...  \n",
            "24780  [ 'young ' , 'buck ' , 'wan ' , 'na ' , 'eat '...  \n",
            "24781  [ 'youu ' , 'got ' , 'wild ' , 'bitch ' , 'tel...  \n",
            "24782  [ 'ruffl ' , 'ntac ' , 'eileen ' , 'dahlia ' ,...  \n",
            "\n",
            "[24783 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Flatten multi-class targets into a single column\n",
        "label_encoder = LabelEncoder()\n",
        "y_true_flat = label_encoder.fit_transform(y_true.values.argmax(axis=1))\n",
        "y_pred_flat = label_encoder.transform(y_pred.values.argmax(axis=1))\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true_flat, y_pred_flat)\n",
        "precision = precision_score(y_true_flat, y_pred_flat, average='weighted')\n",
        "recall = recall_score(y_true_flat, y_pred_flat, average='weighted')\n",
        "f1 = f1_score(y_true_flat, y_pred_flat, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true_flat, y_pred_flat)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os08wZlO4DiG",
        "outputId": "0091c0ba-95fe-43a6-97ab-1b9c54ae27e9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "Confusion Matrix:\n",
            "[[24783]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\n",
        "from keras.optimizers import RMSprop\n",
        "max_words = 50000\n",
        "max_len = 300\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 100, input_length=max_len))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dviPaXF3i3Mi",
        "outputId": "b3483441-4d4f-4646-f71a-32d2b0f39f6b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 300, 100)          5000000   \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 300, 100)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5080501 (19.38 MB)\n",
            "Trainable params: 5080501 (19.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_len)\n"
      ],
      "metadata": {
        "id": "n0QPCXfB-VNs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 for the reserved 0 index\n"
      ],
      "metadata": {
        "id": "kTIgXvsdMVLN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugJlSyI4KTc_",
        "outputId": "b4ec65c3-2bca-4f5b-9ef9-8527b0503d80"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 300, 100)          5000000   \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 300, 100)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5080501 (19.38 MB)\n",
            "Trainable params: 5080501 (19.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming 'tweet' is your text feature, and 'class' is the target variable\n",
        "X = ds['tweet']\n",
        "y = ds['class']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "dt_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = dt_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozuvvI7aaMVu",
        "outputId": "1bd873f0-0cb8-49c7-99c1-703e154a0ea9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8703\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.25      0.28       286\n",
            "           1       0.91      0.94      0.92      3838\n",
            "           2       0.82      0.78      0.80       833\n",
            "\n",
            "    accuracy                           0.87      4957\n",
            "   macro avg       0.69      0.66      0.67      4957\n",
            "weighted avg       0.86      0.87      0.87      4957\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  71  195   20]\n",
            " [ 124 3592  122]\n",
            " [  19  163  651]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Assuming y_true and y_pred are your true and predicted labels\n",
        "# You may need to convert them to a one-dimensional array depending on your data structure\n",
        "y_test_flat = y_test.values.flatten()\n",
        "y_pred_flat = y_pred.values.flatten()\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_flat, y_pred_flat, average='weighted')\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_flat, y_pred_flat, average='weighted')\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test_flat, y_pred_flat, average='weighted')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_flat, y_pred_flat)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "RVeVo8JA8NSU",
        "outputId": "de83557b-923a-4273-fd53-485cd9a09fa7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8f711c359477>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# You may need to convert them to a one-dimensional array depending on your data structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_pred_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
        "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n"
      ],
      "metadata": {
        "id": "ZJiTXH1ZSw_a"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming X_train_sequences and y_train_encoded are lists\n",
        "# Pad sequences to have the same length\n",
        "X_train_sequences_padded = pad_sequences(X_train_sequences, maxlen=max_len)\n",
        "X_train_sequences_array = np.array(X_train_sequences_padded)\n",
        "y_train_encoded_array = np.array(y_train_encoded)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_sequences_array, y_train_encoded_array, epochs=5, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOYykblD8aZp",
        "outputId": "eb8585be-c175-4d18-d42b-c0719a9bd872"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "496/496 [==============================] - 76s 148ms/step - loss: -2.5478 - accuracy: 0.7718 - val_loss: -4.1124 - val_accuracy: 0.7779\n",
            "Epoch 2/5\n",
            "496/496 [==============================] - 67s 136ms/step - loss: -5.7067 - accuracy: 0.7735 - val_loss: -7.0506 - val_accuracy: 0.7779\n",
            "Epoch 3/5\n",
            "496/496 [==============================] - 65s 132ms/step - loss: -8.6478 - accuracy: 0.7735 - val_loss: -9.9273 - val_accuracy: 0.7779\n",
            "Epoch 4/5\n",
            "496/496 [==============================] - 64s 130ms/step - loss: -11.5454 - accuracy: 0.7735 - val_loss: -12.7410 - val_accuracy: 0.7779\n",
            "Epoch 5/5\n",
            "496/496 [==============================] - 65s 130ms/step - loss: -14.4285 - accuracy: 0.7735 - val_loss: -15.5840 - val_accuracy: 0.7779\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ef675ebb880>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you have a single tweet as your input\n",
        "input_tweet = \"Who are you?\"\n",
        "\n",
        "# Preprocess the input\n",
        "input_sequence = tokenizer.texts_to_sequences([input_tweet])\n",
        "input_padded = pad_sequences(input_sequence, maxlen=max_len)\n",
        "\n",
        "# Make predictions\n",
        "prediction = model.predict(input_padded)\n",
        "\n",
        "# Decode the prediction if label encoding was used\n",
        "decoded_prediction = label_encoder.inverse_transform(np.argmax(prediction[0] if prediction.shape else prediction))\n",
        "\n",
        "print(f\"Input Tweet: {input_tweet}\")\n",
        "print(f\"Predicted Class: {decoded_prediction}\")\n"
      ],
      "metadata": {
        "id": "fBfadjvdbSe-",
        "outputId": "4002d864-27a3-428c-c725-ecffd996fc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-03aca1f893ca>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Decode the prediction if label encoding was used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdecoded_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input Tweet: {input_tweet}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# inverse transform of empty array is empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape () instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred_proba = model.predict(X_test_sequence)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Decode labels if needed\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred.flatten())\n",
        "y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
        "classification_rep = classification_report(y_test_labels, y_pred_labels)\n",
        "\n",
        "# Display results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "vEPGes2498VC",
        "outputId": "4c6df39c-6c6e-48b0-c1ea-201eed5ae894"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-84664050aca2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Decode labels if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_seq' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train_padded.shape, y_train_encoded.shape)\n",
        "# print(X_test_padded.shape, y_test_encoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "tbgPDtAeRFLL",
        "outputId": "02d6f5fd-fb24-400f-c568-b0fd8a3dcfc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-388bbecdb0f5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train_encoded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Trim or pad y_train_encoded and y_test_encoded to match the number of samples in X_train_padded and X_test_padded\n",
        "# y_train_encoded_reshaped = y_train_encoded[:X_train_padded.shape[0], :, :]\n",
        "# y_test_encoded_reshaped = y_test_encoded[:X_test_padded.shape[0], :, :]"
      ],
      "metadata": {
        "id": "XN-xDBGURg-3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "23dafba0-6abc-4c89-cb2a-dae4c4dba1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f0df590922e8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Trim or pad y_train_encoded and y_test_encoded to match the number of samples in X_train_padded and X_test_padded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_encoded_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test_encoded_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_test_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train_encoded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# # Assuming 'tweet' is the text column in your dataset\n",
        "# tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust 'max_features' as needed\n",
        "# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['tweet'])\n",
        "\n",
        "# # Now, you can use X_train_tfidf as input feature\n"
      ],
      "metadata": {
        "id": "RdFbbntXbw_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #preprocess train dataset\n",
        "# ds['Num_words_text'] = ds['tweet'].apply(lambda x:len(str(x).split()))\n",
        "\n",
        "# train_data,test_data= train_test_split(ds, test_size=0.2)\n",
        "# train_data.reset_index(drop=True,inplace=True)\n",
        "# test_data.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "etsenWfxVEOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #classes proportion in dependent variable in train and test dataset\n",
        "# print('===========Train Data =========')\n",
        "# print(train_data.value_counts())\n",
        "# print(len(train_data))\n",
        "# print('==============================')\n",
        "\n",
        "# print('===========Test Data =========')\n",
        "# print(test_data.value_counts())\n",
        "# print(len(test_data))\n",
        "# print('==============================')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ASuhz2RcFH2",
        "outputId": "d643d36e-ac3b-4ec6-c88a-39e378f5fe45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========Train Data =========\n",
            "Unnamed: 0  count       hate_speech  offensive_language  neither     class       tweet                                                                           Num_words_text\n",
            "rare_class  rare_class  rare_class   rare_class          rare_class  rare_class  rare_class                                                                      1                 14\n",
            "16897       3           0            3                   0           1           everybodi fckn everybodi bitch amp everybodi shit that life                     9                  1\n",
            "16905       3           0            3                   0           1           fake eyelash okay look natur bitch look like gon na take flight blink fa8230    14                 1\n",
            "16904       3           1            2                   0           1           kobe call dwight howard bitch ass nigga 128514128514 httpstco9l5e8kkw7d         9                  1\n",
            "16903       3           0            3                   0           1           pussi good umma moan um eat                                                     6                  1\n",
            "                                                                                                                                                                                   ..\n",
            "8506        3           1            0                   2           2           cair publish hit list jihadi httptcohvvfxypmhm via red blood american may list  12                 1\n",
            "8505        3           0            3                   0           1           bytch infant hell bitch 18 talk bout much rememb bout pac died187               12                 1\n",
            "8504        3           0            0                   3           2           bye bye charli strong                                                           4                  1\n",
            "8503        3           1            2                   0           1           bye bitch                                                                       2                  1\n",
            "12669       3           0            3                   0           1           let see titti bitch ice cream                                                   6                  1\n",
            "Length: 19813, dtype: int64\n",
            "19826\n",
            "==============================\n",
            "===========Test Data =========\n",
            "Unnamed: 0  count       hate_speech  offensive_language  neither     class       tweet                                                                                                                                     Num_words_text\n",
            "rare_class  rare_class  rare_class   rare_class          rare_class  rare_class  rare_class                                                                                                                                1                 2\n",
            "16917       3           1            2                   0           1           twitter fye nigga use go trend topics8230now recycl tweet hoe scream want loy8230                                                         13                1\n",
            "16955       3           0            3                   0           1           shout bitch think boyfriend loyal everi time check phone say 0 inbox                                                                      12                1\n",
            "16940       3           0            3                   0           1           dick call batman bitch love dark knight rise                                                                                              8                 1\n",
            "16936       3           0            3                   0           1           citi bitch 128514128514128514128514starbuck uggboot jellydoughnut httpstcovvit8hp40t                                                      6                 1\n",
            "                                                                                                                                                                                                                                            ..\n",
            "8431        3           0            3                   0           1           bruh im readi get four wheeler bitch fast asf                                                                                             9                 1\n",
            "8430        3           0            3                   0           1           brrr hoe dichter bij het sint gebeuren hoe racistisch de drek op twitter en het komt nagenoeg alleen van de prozwartepieten hoek engvolk  23                1\n",
            "8429        6           0            0                   6           2           brown redskin shouldnt consid nfl team                                                                                                    6                 1\n",
            "8423        3           1            2                   0           1           broke pussi boy deion record                                                                                                              5                 1\n",
            "12845       3           0            0                   3           2           lmaoooo bird hand worth two bush httptco50ye6jaadu                                                                                        7                 1\n",
            "Length: 4956, dtype: int64\n",
            "4957\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from collections import Counter\n",
        "# #train and validation dataset splitting\n",
        "# X_train, X_valid, Y_train, Y_valid = train_test_split(train_data['tweet'].tolist(),\\\n",
        "#                                                       train_data['class'].tolist(),\\\n",
        "\n",
        "#                                                       test_size=0.2,\\\n",
        "#                                                       stratify = train_data['class'].tolist(),\\\n",
        "#                                                       random_state=0)\n",
        "\n",
        "\n",
        "# print('Train data len:'+str(len(X_train)))\n",
        "# print('Class distribution'+str(Counter(Y_train)))\n",
        "# print('Valid data len:'+str(len(X_valid)))\n",
        "# print('Class distribution'+ str(Counter(Y_valid)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN2-B-bm9QtX",
        "outputId": "cfca4c8f-aa09-4b7b-e6f7-fa6554a2e1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data len:15860\n",
            "Class distributionCounter({1: 12268, 2: 2662, 0: 919, 'rare_class': 11})\n",
            "Valid data len:3966\n",
            "Class distributionCounter({1: 3067, 2: 666, 0: 230, 'rare_class': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# #convert sentences to sequences of numbers\n",
        "# x_train = np.array( tokenizer.texts_to_sequences(X_train) )\n",
        "# x_valid = np.array( tokenizer.texts_to_sequences(X_valid) )\n",
        "# x_test  = np.array( tokenizer.texts_to_sequences(test_data['tweet'].tolist()) )\n",
        "\n",
        "# y_train = np.array(Y_train)\n",
        "# y_valid = np.array(Y_valid)\n",
        "# y_test  = np.array( tokenizer.texts_to_sequences(test_data['tweet'].tolist()) )\n",
        "\n",
        "# #padding\n",
        "# maxlen=50\n",
        "# x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "# x_valid = pad_sequences(x_valid, padding='post', maxlen=maxlen)\n",
        "# x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "# train_labels = np.asarray(y_train)\n",
        "# valid_labels = np.asarray(y_valid)\n",
        "# test_labels = np.asarray(test_data['count'].tolist())\n",
        "\n",
        "\n",
        "# print('Train data len:'+str(len(x_train)))\n",
        "# print('Class distribution'+str(Counter(train_labels)))\n",
        "\n",
        "# print('Validation data len:'+str(len(x_valid)))\n",
        "# print('Class distribution'+str(Counter(valid_labels)))\n",
        "\n",
        "# print('Test data len:'+str(len(x_test)))\n",
        "# print('Class distribution'+str(Counter(test_labels)))\n",
        "\n",
        "# #tensorflow dataset preparation\n",
        "# train_ds = tf.data.Dataset.from_tensor_slices((x_train,train_labels))\n",
        "# valid_ds = tf.data.Dataset.from_tensor_slices((x_valid,valid_labels))\n",
        "# test_ds = tf.data.Dataset.from_tensor_slices((x_test,test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmtRD5rnPhwF",
        "outputId": "e2971214-3764-4cff-c0e4-20925b00ba3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-264e17f768ac>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_train = np.array( tokenizer.texts_to_sequences(X_train) )\n",
            "<ipython-input-42-264e17f768ac>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_valid = np.array( tokenizer.texts_to_sequences(X_valid) )\n",
            "<ipython-input-42-264e17f768ac>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_test  = np.array( tokenizer.texts_to_sequences(test_data['tweet'].tolist()) )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data len:15860\n",
            "Class distributionCounter({'1': 12268, '2': 2662, '0': 919, 'rare_class': 11})\n",
            "Validation data len:3966\n",
            "Class distributionCounter({'1': 3067, '2': 666, '0': 230, 'rare_class': 3})\n",
            "Test data len:4957\n",
            "Class distributionCounter({'3': 4565, '6': 306, '4': 49, '9': 27, '7': 8, 'rare_class': 2})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-264e17f768ac>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_test  = np.array( tokenizer.texts_to_sequences(test_data['tweet'].tolist()) )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# vect = TfidfVectorizer(ngram_range=(1,2)).fit(ds['tweet'])"
      ],
      "metadata": {
        "id": "hEpfpLnKMj4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from keras import regularizers\n",
        "\n",
        "# logreg= LogisticRegression()\n",
        "# logreg.fit(x_train, y_train)\n",
        "# logreg_predict= logreg.predict(x_test)\n",
        "# logreg_acc= accuracy_score(logreg_predict, test_labels)\n",
        "# print(\"test accuracy:{:.2f}%\".format(logreg_acc*100))\n",
        "# # model preparation\n",
        "# max_features =50000\n",
        "# embedding_dim =16\n",
        "# sequence_length = maxlen\n",
        "\n",
        "# model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Embedding(max_features +1, embedding_dim, input_length=sequence_length,\\\n",
        "#                                     embeddings_regularizer = regularizers.l2(0.005)))\n",
        "# model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "# model.add(tf.keras.layers.LSTM(embedding_dim,dropout=0.2, recurrent_dropout=0.2,return_sequences=True,\\\n",
        "#                                                              kernel_regularizer=regularizers.l2(0.005),\\\n",
        "#                                                              bias_regularizer=regularizers.l2(0.005)))\n",
        "\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# model.add(tf.keras.layers.Dense(512, activation='relu',\\\n",
        "#                                 kernel_regularizer=regularizers.l2(0.001),\\\n",
        "#                                 bias_regularizer=regularizers.l2(0.001),))\n",
        "# model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "# model.add(tf.keras.layers.Dense(8, activation='relu',\\\n",
        "#                                 kernel_regularizer=regularizers.l2(0.001),\\\n",
        "#                                 bias_regularizer=regularizers.l2(0.001),))\n",
        "# model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "\n",
        "# model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "\n",
        "# model.summary()\n",
        "# model.compile(loss=tf.keras.losses.BinaryCrossentropy(),optimizer=tf.keras.optimizers.Adam(1e-3),metrics=[tf.keras.metrics.BinaryAccuracy()])"
      ],
      "metadata": {
        "id": "XxiHbHmlW8-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a684a8-0e98-4427-bd0d-27e01680f57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy:0.00%\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 50, 16)            800016    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 50, 16)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50, 16)            2112      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               410112    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 4104      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1216353 (4.64 MB)\n",
            "Trainable params: 1216353 (4.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #make predictions on validation dataset\n",
        "# valid_predict= model.predict(x_valid)\n",
        "# print(valid_predict[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mE_vSIRwAjun",
        "outputId": "64d9ce4d-79dd-4aba-e514-fb33ba91d5c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-65566372a716>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#make predictions on validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalid_predict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_valid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #model's metrics on test dataset\n",
        "# x_test  = np.array( tokenizer.texts_to_sequences(test_data['tweet'].tolist()) )\n",
        "# x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "# #Generate predictions for all samples\n",
        "# predictions = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXB4VZIzAojS",
        "outputId": "a787aa33-c865-4323-a33a-bd30a3af427d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-78bc6703b6ef>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_test  = np.array( tokenizer.texts_to_sequences(test_data['tweet'].tolist()) )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 3s 18ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Unique classes in y_train:\", np.unique(y_train))\n",
        "# print(\"Unique classes in y_valid:\", np.unique(y_valid))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "NHbA2zmEAuFT",
        "outputId": "f2481e19-f939-4901-f7df-893a1f7be32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes in y_train: [0 1 2]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-1d8f1771022b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unique classes in y_train:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unique classes in y_valid:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_valid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "# from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# num_classes = 10\n",
        "# label_encoder = LabelEncoder()\n",
        "# y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "# y_valid_encoded = label_encoder.fit_transform(y_valid)\n",
        "\n",
        "# y_train_categorical = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "# y_valid_categorical = to_categorical(y_valid_encoded, num_classes=num_classes)\n",
        "\n",
        "# # Padding sequences to a consistent length\n",
        "# maxlen = 50\n",
        "# x_train_padded = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "# x_valid_padded = pad_sequences(x_valid, padding='post', maxlen=maxlen)\n",
        "\n",
        "# # Convert to NumPy arrays\n",
        "# x_train_array = np.array(x_train_padded)\n",
        "# x_valid_array = np.array(x_valid_padded)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(232337, 100, input_length=maxlen))\n",
        "# model.add(SpatialDropout1D(0.2))\n",
        "# model.add(LSTM(20, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# epochs = 25\n",
        "# batch_size = 64\n",
        "# history = model.fit(x_train_array, y_train_categorical, validation_data=(x_valid_array, y_valid_categorical), epochs=epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfyW56V3A1JJ",
        "outputId": "f9aa1c81-28e1-4250-cd4f-7a22294fc959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "248/248 [==============================] - 174s 685ms/step - loss: 0.8435 - accuracy: 0.7680 - val_loss: 0.6774 - val_accuracy: 0.7733\n",
            "Epoch 2/25\n",
            "248/248 [==============================] - 176s 710ms/step - loss: 0.6748 - accuracy: 0.7735 - val_loss: 0.6727 - val_accuracy: 0.7733\n",
            "Epoch 3/25\n",
            "248/248 [==============================] - 167s 672ms/step - loss: 0.6720 - accuracy: 0.7735 - val_loss: 0.6707 - val_accuracy: 0.7733\n",
            "Epoch 4/25\n",
            "248/248 [==============================] - 163s 658ms/step - loss: 0.6703 - accuracy: 0.7735 - val_loss: 0.6701 - val_accuracy: 0.7733\n",
            "Epoch 5/25\n",
            "248/248 [==============================] - 165s 663ms/step - loss: 0.6700 - accuracy: 0.7735 - val_loss: 0.6701 - val_accuracy: 0.7733\n",
            "Epoch 6/25\n",
            "248/248 [==============================] - 175s 707ms/step - loss: 0.6701 - accuracy: 0.7735 - val_loss: 0.6721 - val_accuracy: 0.7733\n",
            "Epoch 7/25\n",
            "248/248 [==============================] - 165s 666ms/step - loss: 0.6696 - accuracy: 0.7735 - val_loss: 0.6700 - val_accuracy: 0.7733\n",
            "Epoch 8/25\n",
            "248/248 [==============================] - 166s 668ms/step - loss: 0.6695 - accuracy: 0.7735 - val_loss: 0.6695 - val_accuracy: 0.7733\n",
            "Epoch 9/25\n",
            "248/248 [==============================] - 163s 658ms/step - loss: 0.6696 - accuracy: 0.7735 - val_loss: 0.6702 - val_accuracy: 0.7733\n",
            "Epoch 10/25\n",
            "248/248 [==============================] - 180s 727ms/step - loss: 0.6697 - accuracy: 0.7735 - val_loss: 0.6703 - val_accuracy: 0.7733\n",
            "Epoch 11/25\n",
            "248/248 [==============================] - 164s 662ms/step - loss: 0.6692 - accuracy: 0.7735 - val_loss: 0.6707 - val_accuracy: 0.7733\n",
            "Epoch 12/25\n",
            "248/248 [==============================] - 165s 665ms/step - loss: 0.6694 - accuracy: 0.7735 - val_loss: 0.6692 - val_accuracy: 0.7733\n",
            "Epoch 13/25\n",
            "248/248 [==============================] - 178s 717ms/step - loss: 0.6698 - accuracy: 0.7735 - val_loss: 0.6692 - val_accuracy: 0.7733\n",
            "Epoch 14/25\n",
            "248/248 [==============================] - 165s 664ms/step - loss: 0.6690 - accuracy: 0.7735 - val_loss: 0.6697 - val_accuracy: 0.7733\n",
            "Epoch 15/25\n",
            "248/248 [==============================] - 163s 659ms/step - loss: 0.6688 - accuracy: 0.7735 - val_loss: 0.6693 - val_accuracy: 0.7733\n",
            "Epoch 16/25\n",
            "248/248 [==============================] - 167s 673ms/step - loss: 0.6692 - accuracy: 0.7735 - val_loss: 0.6701 - val_accuracy: 0.7733\n",
            "Epoch 17/25\n",
            "248/248 [==============================] - 178s 716ms/step - loss: 0.6691 - accuracy: 0.7735 - val_loss: 0.6705 - val_accuracy: 0.7733\n",
            "Epoch 18/25\n",
            "248/248 [==============================] - 165s 665ms/step - loss: 0.6692 - accuracy: 0.7735 - val_loss: 0.6696 - val_accuracy: 0.7733\n",
            "Epoch 19/25\n",
            "248/248 [==============================] - 165s 667ms/step - loss: 0.6691 - accuracy: 0.7735 - val_loss: 0.6704 - val_accuracy: 0.7733\n",
            "Epoch 20/25\n",
            "248/248 [==============================] - 163s 657ms/step - loss: 0.6694 - accuracy: 0.7735 - val_loss: 0.6707 - val_accuracy: 0.7733\n",
            "Epoch 21/25\n",
            "248/248 [==============================] - 180s 724ms/step - loss: 0.6692 - accuracy: 0.7735 - val_loss: 0.6693 - val_accuracy: 0.7733\n",
            "Epoch 22/25\n",
            "248/248 [==============================] - 162s 654ms/step - loss: 0.6691 - accuracy: 0.7735 - val_loss: 0.6701 - val_accuracy: 0.7733\n",
            "Epoch 23/25\n",
            "248/248 [==============================] - 164s 661ms/step - loss: 0.6695 - accuracy: 0.7735 - val_loss: 0.6695 - val_accuracy: 0.7733\n",
            "Epoch 24/25\n",
            "248/248 [==============================] - 175s 705ms/step - loss: 0.6689 - accuracy: 0.7735 - val_loss: 0.6698 - val_accuracy: 0.7733\n",
            "Epoch 25/25\n",
            "248/248 [==============================] - 165s 664ms/step - loss: 0.6699 - accuracy: 0.7735 - val_loss: 0.6698 - val_accuracy: 0.7733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6oyML5PK7N-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}